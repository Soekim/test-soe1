import numpy as np
from tensorflow import keras
import tensorflow as tf
from tensorflow.keras import losses
from matplotlib import pyplot as plt
from keras.models import Sequential
from tensorflow.keras.layers import * 
from tensorflow.keras.models import Model

# Download MNIST dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# data 전처리 수행
# calculate the sample mean and std
mu = x_train.mean()

# 0으로 나누는 것을 방지하기 위해서 매우 작은 값을 더해준다.
sig = x_train.std()+0.000000001

# normalize (z-score)
x_train = (x_train - mu) / sig

# train set과 동일한 평균과 표준편차로 test_set도 변경해줘야한다.
x_test = (x_test - mu) / sig 

# Change the shape of data from (W, W) to (W*W, )
# 여기서는 마지막에 1은 흑백사진이므로 채널을 맞춰주기 위해서 써준다.
x_train = x_train.reshape((-1, 28,28,1))
x_test = x_test.reshape((-1, 28,28,1))

# convert class vectors to binary class matrices 
y_train = keras.utils.to_categorical(y_train,10)
y_test = keras.utils.to_categorical(y_test,10)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

plt.figure()
plt.imshow(x_train[1].reshape(28,28))
plt.show()

## Model
## 2-layer CNN with MLP
# check the #parameters! (only 10% of MLP)
# filter의 갯수만큼 output 개수가 나오며, 여기서 filter는 동일한 (3,3) 필터 개수를 몇 개 사용할 것인지에 대한 것
# pooling layer를 쓰는 이유는 demesion reducton과 max값인 것이 예측하는 데 더 많은 정보가 들어있다고 생각

# 3*3(필터사이즈) * 1 (입력채널 , RGB) * 32개 (필터갯수) + 32 (필터 BIAS) = 320개
# 3*3 (필터사이즈) * 32 (입력채널 갯수) * 32개 (필터갯수) + 32 (필터 BIAS)= 9248개

model = keras.Sequential(
    [
      Conv2D(
        filters=32,
        kernel_size=(3,3),
        strides=(1, 1),
        padding="valid",
        activation='relu',
        input_shape=(28,28,1)
      ),
      Conv2D(
        filters=32,
        kernel_size=(3,3),
        strides=(1, 1),
        padding="valid",
        activation='relu',
      ),
      MaxPooling2D(
       pool_size=(2, 2), strides=None, padding="valid"
       ),
     Flatten(),
    #  hidden layer를 써도 됨
    #  Dense(100,activation='relu'),
        
     Dense(10,activation='softmax')
    ],
    
)

model.summary()

## Train
batch_size = 64
epochs = 50

## compile
# Learning rate / loss / optimaizer 등
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
## fit
hist = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)

### MNIST Classifier with CNN 

## plot loss and accuracy to check if the model is converged.
val_accuracy = hist.history['val_accuracy']
train_accuracy = hist.history['accuracy']

# x축을 epochs
from matplotlib import pyplot as plt
plt.figure()
plt.grid()
plt.plot(np.arange(epochs),val_accuracy,label="val_accuracy")
plt.plot(np.arange(epochs),train_accuracy,label="train_accuracy")
plt.legend()
plt.show()

# 모델 평가하기
print('##### Test Result #####')
score = model.evaluate(x_test, y_test, verbose=1)
print(f'Test Loss : {score[0]}')
print(f'Test Accuracy : {score[1]}')

# # 모델 저장하기(모델 학습이 오래걸리는 경우 저장해두고 불러와서 사용)
# #필요에 따라 사용
# import tensorflow as tf
# from keras.models import load_model, save_model
# model.save('my_model.h5')

# # 기존 모델 불러오기(학습이 완료된 저장 모델 불러와서 사용하기)
# new_model=tf.keras.models.load_model('my_ai.h5')
# new_model.summary()

### ------ 2번 문항 ------ ###

## 이미지 Noise 제거
# 각 이미지에 임의의 노이즈를 적용하여 MNIST 데이터세트의 노이즈 버전 생성
# 이후 노이즈가 있는 이미지를 입력으로 사용하고 원본 이미지를 대상으로 사용하여 autoencoder 훈련
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]

print(x_train.shape)


# ### MNIST Classifier with real hand writing
import tensorflow as tf
from keras.layers import Dense

noise_factor = 0.2
x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) 
x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) 

x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)
x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)

# 문제에서 주어진 x_test_noisy로 Noise가 있는 이미지 플롯

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
    ax = plt.subplot(1, n, i + 1)
    plt.title("original + noise")
    plt.imshow(tf.squeeze(x_test_noisy[i]))
    plt.gray()
plt.show()

input_img = Input(shape=(28, 28, 1))  # 'channels_firtst'이미지 데이터 형식을 사용하는 경우 이를 적용 

x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)

# encoder의 shape = (samples, 4, 4, 8) 
encoded = MaxPooling2D((2, 2), padding='same')(x) 


x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = UpSampling2D((2, 2))(x)

decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x) # decoder의 shape = (sampels, 28, 28, 1) 
denoise = Model(input_img, decoded)
denoise.compile(optimizer='adam', loss='binary_crossentropy')

denoise.fit(
    x_train_noisy, x_train,                 
    batch_size=256, epochs=20,                 
    validation_data=(x_test_noisy,x_test)
)

decoded_imgs = denoise.predict(x_test_noisy)

denoise.summary()

# 원본+노이즈 이미지와 복원된 이미지(원본과 가까운) 확인

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):

    # display original + noise
    ax = plt.subplot(2, n, i + 1)
    plt.title("original + noise")
    plt.imshow(tf.squeeze(x_test_noisy[i]))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    bx = plt.subplot(2, n, i + n + 1)
    plt.title("reconstructed")
    plt.imshow(tf.squeeze(decoded_imgs[i]))
    plt.gray()
    bx.get_xaxis().set_visible(False)
    bx.get_yaxis().set_visible(False)
plt.show()


