머신러닝을 위한 가장 기본적인 데이터셋인 MNIST 데이터셋은 0 ~ 9까지의 숫자 손글씨를 저장해놓은 데이터 베이스이다.
![image.png](attachment:image.png)
MNIST 데이터 셋은 28x28의 1채널 흑백 영상이고 원본 데이터는 각 픽셀별 0 ~ 255까지 8bit 정수형 변수를 갖는다. 이를 일반적으로 활용할 때에는 픽셀별 값을 아래와 같이 0 ~ 1사이로 표준화 하여 사용한다. 
![image-2.png](attachment:image-2.png)

1. 아래와 같이 MNIST 데이터 셋을 TF 에서 다운로드 받으면 총 60000개의 학습용 데이터와 10000개의 검증용 데이터를 다운 받을 수 있다.

import numpy as np
from tensorflow import keras
import tensorflow as tf
from tensorflow.keras import layers, losses
from matplotlib import pyplot as plt
from keras.models import Sequential
from tensorflow.keras.models import Model

# Download MNIST dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# data 전처리 수행
# calculate the sample mean and std
mu = x_train.mean()

# 0으로 나누는 것을 방지하기 위해서 매우 작은 값을 더해준다.
sig = x_train.std()+0.000000001

# normalize (z-score)
x_train = (x_train - mu) / sig

# train set과 동일한 평균과 표준편차로 test_set도 변경해줘야한다.
x_test = (x_test - mu) / sig 

# Change the shape of data from (W, W) to (W*W, )
# 여기서는 마지막에 1은 흑백사진이므로 채널을 맞춰주기 위해서 써준다.
x_train = x_train.reshape((-1, 28,28,1))
x_test = x_test.reshape((-1, 28,28,1))

# convert class vectors to binary class matrices 
y_train = keras.utils.to_categorical(y_train,10)
y_test = keras.utils.to_categorical(y_test,10)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

# sample 확인
# data sample
plt.figure()
plt.imshow(x_train[1].reshape(28,28))
plt.show()

## Model
## 2-layer CNN with MLP
# check the #parameters! (only 10% of MLP)
# filter의 갯수만큼 output 개수가 나오며, 여기서 filter는 동일한 (3,3) 필터 개수를 몇 개 사용할 것인지에 대한 것
# pooling layer를 쓰는 이유는 demesion reducton과 max값인 것이 예측하는 데 더 많은 정보가 들어있다고 생각

# 3*3(필터사이즈) * 1 (입력채널 , RGB) * 32개 (필터갯수) + 32 (필터 BIAS) = 320개
# 3*3 (필터사이즈) * 32 (입력채널 갯수) * 32개 (필터갯수) + 32 (필터 BIAS)= 9248개

model = keras.Sequential(
    [
      keras.layers.Conv2D(
        filters=32,
        kernel_size=(3,3),
        strides=(1, 1),
        padding="valid",
        activation='relu',
        input_shape=(28,28,1)
      ),
      keras.layers.Conv2D(
        filters=32,
        kernel_size=(3,3),
        strides=(1, 1),
        padding="valid",
        activation='relu',
      ),
     keras.layers.MaxPooling2D(
       pool_size=(2, 2), strides=None, padding="valid"
       ),
     layers.Flatten(),
    #  hidden layer를 써도 됨
    #  layers.Dense(100,activation='relu'),
     layers.Dense(10,activation='softmax')
    ],
    
)

model.summary()

## Train
batch_size = 64
epochs = 50

## compile
# Learning rate / loss / optimaizer 등
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) # keras.losses.MeanSq
## fit
hist = model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)

2. 위에서 다운받은 MNIST 데이터 셋중 학습용 데이터 셋을 이용하여 MNIST 데이터 셋을 분류할 수 있는 간단한 Covolutional Neural Network 분류기를 만들과, 검증용 데이터 셋으로 성능을 검증하시오.
 - 데이터 전처리 및 신경망의 모델은 사용자가 선택한 전략에 따라 구현하시오.

### MNIST Classifier with CNN 

## plot loss and accuracy to check if the model is converged.
val_accuracy = hist.history['val_accuracy']
train_accuracy = hist.history['accuracy']

# x축을 epochs
from matplotlib import pyplot as plt
plt.figure()
plt.grid()
plt.plot(np.arange(epochs),val_accuracy,label="val_accuracy")
plt.plot(np.arange(epochs),train_accuracy,label="train_accuracy")
plt.legend()
plt.show()

# 모델 평가하기
print('##### Test Result #####')
score = model.evaluate(x_test, y_test, verbose=1)
print(f'Test Loss : {score[0]}')
print(f'Test Accuracy : {score[1]}')

# 모델 저장하기
import tensorflow as tf
from keras.models import load_model, save_model
model.save('my_model.h5')

3. 아래와 MNIST 데이터셋에 약간의 강제 잡음을 추가한 데이터를 생성하였다.
![image-3.png](attachment:image-3.png) ![image-2.png](attachment:image-2.png)

1. 위와 같이 noise가 추가 된, noise 데이터와 원본 데이터를 활용하여, noise를 제거하여 원본데이터처럼 복원을 해주는  denoising auto encoder알고리즘을 구현하시오.
 - AE의 네트워크 구조등은 직접 판단하여 구현하시오.

## 1) 기본 데이터 autoencoding (기존 데이터의 인코딩/디코딩 확인)
# 기존 모델 불러오기

new_model=tf.keras.models.load_model('my_model.h5')
new_model.summary()

# MNIST 데이터세트 사용하여 기본 autoencoder 훈련
# 데이터세트 각 이미지는 28x28 픽셀

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

print (x_train.shape)
print (x_test.shape)

## 두개의 Dense 레이어로 autoencoder 정의
# 이미지를 64차원 잠재 벡터로 압축하는 encoder와 잠재공간에서 원본 이미지 재구성하는 decoder

latent_dim = 64 

class Autoencoder(Model):
  def __init__(self, latent_dim):
    super(Autoencoder, self).__init__()
    self.latent_dim = latent_dim   
    self.encoder = tf.keras.Sequential([
      layers.Flatten(),
      layers.Dense(latent_dim, activation='relu'),
    ])
    self.decoder = tf.keras.Sequential([
      layers.Dense(784, activation='sigmoid'),
      layers.Reshape((28, 28))
    ])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Autoencoder(latent_dim)

autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())

# x_train 입력과 대상으로 사용하여 모델 훈련
# encoder는 데이터 세트를 784차원에서 잠재 공간으로 압축 학습
# decoder는 원본 이미지 재구성하는 방법 학습

autoencoder.fit(x_train, x_train,
                epochs=10,
                shuffle=True,
                validation_data=(x_test, x_test))

# encoding & decoding test
encoded_imgs = autoencoder.encoder(x_test).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
  # display original
  ax = plt.subplot(2, n, i + 1)
  plt.imshow(x_test[i])
  plt.title("original")
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # display reconstruction
  ax = plt.subplot(2, n, i + 1 + n)
  plt.imshow(decoded_imgs[i])
  plt.title("reconstructed")
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
plt.show()

## 2) 이미지 Noise 제거
# 각 이미지에 임의의 노이즈를 적용하여 MNIST 데이터세트의 노이즈 버전 생성
# 이후 노이즈가 있는 이미지를 입력으로 사용하고 원본 이미지를 대상으로 사용하여 autoencoder 훈련
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

x_train = x_train[..., tf.newaxis]
x_test = x_test[..., tf.newaxis]

print(x_train.shape)

# ### MNIST Classifier with real hand writing
import tensorflow as tf
from keras.layers import Dense

noise_factor = 0.2
x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) 
x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) 

x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)
x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)

# 문제에서 주어진 x_test_noisy로 Noise가 있는 이미지 플롯

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
    ax = plt.subplot(1, n, i + 1)
    plt.title("original + noise")
    plt.imshow(tf.squeeze(x_test_noisy[i]))
    plt.gray()
plt.show()

# Convolutional autoencoder 정의
# encoder에 Conv2D 레이어를 사용하고 decoder에 Conv2DTranspose 레이어를 사용하여 컨볼루셔널 autoencoder를 훈련

class Denoise(Model):
  def __init__(self):
    super(Denoise, self).__init__()
    self.encoder = tf.keras.Sequential([
      layers.Input(shape=(28, 28, 1)), 
      layers.Conv2D(16, (3,3), activation='relu', padding='same', strides=2),
      layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2)])

    self.decoder = tf.keras.Sequential([
      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),
      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),
      layers.Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='same')])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Denoise()

autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())

autoencoder.fit(x_train_noisy, x_train,
                epochs=10,
                shuffle=True,
                validation_data=(x_test_noisy, x_test))

# 28x28 to 7x7 down sampling 확인
autoencoder.encoder.summary()

# decoder는 이미지를 7x7에서 28x28로 Up sampling

autoencoder.decoder.summary()

# autoencoder에서 생성된 노이즈가 있는 이미지와 노이즈가 제거 된 이미지를 모두 플롯

encoded_imgs = autoencoder.encoder(x_test).numpy()
decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()


# 원본+노이즈 이미지와 원본과 가깝게 복원된 이미지 확인

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):

    # display original + noise
    ax = plt.subplot(2, n, i + 1)
    plt.title("original + noise")
    plt.imshow(tf.squeeze(x_test_noisy[i]))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    bx = plt.subplot(2, n, i + n + 1)
    plt.title("reconstructed")
    plt.imshow(tf.squeeze(decoded_imgs[i]))
    plt.gray()
    bx.get_xaxis().set_visible(False)
    bx.get_yaxis().set_visible(False)
plt.show()
